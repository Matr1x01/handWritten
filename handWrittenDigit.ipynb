{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('tf-amd': conda)"
  },
  "interpreter": {
   "hash": "c94e96bb83342a8b97e318fe3610a28face5210a30124b5ebd62cb5df9d4f7d9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models,layers,Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"G:\\dataset\\handWriting\\trainingSet\\trainingSet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size =(28,28,1)\n",
    "hidden1 = 512\n",
    "hidden2 = 256\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirPath, dirName, files = next(os.walk(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "G:\\dataset\\handWriting\\trainingSet\\trainingSet\\0\n",
      "G:\\dataset\\handWriting\\trainingSet\\trainingSet\\1\n",
      "G:\\dataset\\handWriting\\trainingSet\\trainingSet\\2\n",
      "G:\\dataset\\handWriting\\trainingSet\\trainingSet\\3\n",
      "G:\\dataset\\handWriting\\trainingSet\\trainingSet\\4\n",
      "G:\\dataset\\handWriting\\trainingSet\\trainingSet\\5\n",
      "G:\\dataset\\handWriting\\trainingSet\\trainingSet\\6\n",
      "G:\\dataset\\handWriting\\trainingSet\\trainingSet\\7\n",
      "G:\\dataset\\handWriting\\trainingSet\\trainingSet\\8\n",
      "G:\\dataset\\handWriting\\trainingSet\\trainingSet\\9\n"
     ]
    }
   ],
   "source": [
    "for dirs in dirName:\n",
    "    nowDir = path+\"\\\\\"+dirs\n",
    "    print(nowDir)\n",
    "    nowfiles = os.listdir(nowDir)\n",
    "    for file in nowfiles:\n",
    "        nowPath = nowDir+\"\\\\\"+file\n",
    "        img = Image.open(nowPath)\n",
    "        img = np.asarray(img)\n",
    "        X_train.append(img.reshape(input_size))\n",
    "        Y_train.append(int(dirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = np.array(X_train).astype(\"float32\"), np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= 255\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X_train, Y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Matrix\\.conda\\envs\\tf-amd\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Conv2D(16, 3, activation='relu', padding='same',input_shape=input_size))\n",
    "model.add(layers.Conv2D(8, 3, activation='relu', padding='same'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(layers.Dense(hidden1, activation='relu'))\n",
    "model.add(layers.Dense(hidden2, activation='relu'))\n",
    "model.add(layers.Dense(output_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 33600 samples\n",
      "Epoch 1/10\n",
      "33600/33600 - 30s - loss: 0.5553 - acc: 0.8415\n",
      "Epoch 2/10\n",
      "33600/33600 - 29s - loss: 0.1816 - acc: 0.9437\n",
      "Epoch 3/10\n",
      "33600/33600 - 29s - loss: 0.1341 - acc: 0.9587\n",
      "Epoch 4/10\n",
      "33600/33600 - 30s - loss: 0.1051 - acc: 0.9682\n",
      "Epoch 5/10\n",
      "33600/33600 - 29s - loss: 0.0889 - acc: 0.9727\n",
      "Epoch 6/10\n",
      "33600/33600 - 29s - loss: 0.0729 - acc: 0.9772\n",
      "Epoch 7/10\n",
      "33600/33600 - 29s - loss: 0.0659 - acc: 0.9793\n",
      "Epoch 8/10\n",
      "33600/33600 - 29s - loss: 0.0573 - acc: 0.9817\n",
      "Epoch 9/10\n",
      "33600/33600 - 30s - loss: 0.0511 - acc: 0.9841\n",
      "Epoch 10/10\n",
      "33600/33600 - 30s - loss: 0.0434 - acc: 0.9862\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'], optimizer='sgd')\n",
    "\n",
    "history=model.fit(X_train, Y_train, batch_size=64, epochs=10, verbose=2)\n",
    "model.save(\"handWritten.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "33600/33600 [==============================] - 10s 310us/sample - loss: 0.0323 - acc: 0.9905\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.03225332807269989, 0.9904762]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "model.evaluate(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8400/8400 [==============================] - 3s 313us/sample - loss: 0.0885 - acc: 0.9735\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.0885169613281531, 0.9734524]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}